{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA2_SNjzA4Dc"
      },
      "source": [
        "# Consumer Memory Agent\n",
        "**Applying a multimodal thread of reasoning to customer service**     \n",
        "copyright 2025, Denis Rothman\n",
        "\n",
        "The goal of this notebook is to develop a consumer memory agent that applies neuroscience-inspired memory tagging to customer reviews, enabling the generation of personalized messages.\n",
        "\n",
        "**Table of Contents**\n",
        "\n",
        "1. **Setting up the environment**\n",
        "\n",
        "2. **The dataset: hotel reviews**\n",
        "\n",
        "3. **Agent Memory Functions**\n",
        "   - Querying Agent Memory\n",
        "   - Upserting Functions\n",
        "   - Memory Structure\n",
        "\n",
        "4. **Building the Agent's Memory Structure**\n",
        "    - Memory Hierarchy\n",
        "    - Visualizing Memory Categories\n",
        "\n",
        "5. **Strategic consumer agent memory**\n",
        "    - Hotel Reviews Analysis\n",
        "    - Sentiment Analysis and Memory Tagging\n",
        "    - Creating Marketing Content\n",
        "    - Image and Customer Message Generation\n",
        "\n",
        "**Note**: *This notebook is for educational purposes only. It is not designed to be deployed into production.*\n",
        "\n",
        "This notebook uses OpenAI GPT Models. https://openai.com\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vub82Rjxa17a"
      },
      "source": [
        "# Setting up the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook was developed in Google Colab. Colab includes many pre-installed libraries and sets `/content/` as the default directory, meaning you can access files directly by their filename if you wish (e.g., `filename` instead of needing to specify `/content/filename`). This differs from local environments, where you'll often need to install libraries or specify full file paths."
      ],
      "metadata": {
        "id": "Nb0mHg3p4yBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing `click` and gTTS\n",
        "\n",
        "**If you want to use text-to-speech in this notebook with `gTTS`, set `use_gtts` to `True` in the following cell.**\n",
        "\n",
        "`click`, a command line library, is required for gTTS. This cell will set up the correct 'click' version required for gTTS and *display a restart message*. After restarting, simply click `Run All` to continue.\n",
        "\n",
        "*The restart is necessary for Colab to take the new version into account.*\n",
        "\n"
      ],
      "metadata": {
        "id": "eDh9bnDga1P-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_gtts = False #activates Google TTS in Google Colab if True and deactivates if False"
      ],
      "metadata": {
        "id": "blegAI_Aa1P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Conditional 'click' setup.\n",
        "# This cell will only modify 'click' IF the 'click' version is not 8.1.8.\n",
        "# If changes are made, a clear message will appear in the output, instructing you to restart the session.\n",
        "# After restarting, Colab will reconnect, and you can simply \"Run All\" from the top.\n",
        "\n",
        "import importlib.metadata\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Import for displaying rich output (HTML)\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "#---Begin gTTS True or\n",
        "current_click_version = None\n",
        "try:\n",
        "    current_click_version = importlib.metadata.version('click')\n",
        "except importlib.metadata.PackageNotFoundError:\n",
        "    pass\n",
        "\n",
        "if not use_gtts:\n",
        "    required_click_version = current_click_version\n",
        "else:\n",
        "    required_click_version = '8.1.8'\n",
        "#---END gTTS True or False\n",
        "print(\"--- Checking 'click' package version... ---\")\n",
        "\n",
        "try:\n",
        "    current_click_version = importlib.metadata.version('click')\n",
        "    print(f\"Currently installed 'click' version: {current_click_version}\")\n",
        "except importlib.metadata.PackageNotFoundError:\n",
        "    print(\"'click' package not found.\")\n",
        "\n",
        "# Check if current click version is not the required one\n",
        "if current_click_version != required_click_version:\n",
        "    print(f\"\\n--- 'click' version is not {required_click_version}. Initiating setup... ---\")\n",
        "\n",
        "    print(\"Uninstalling any existing 'click' installation...\")\n",
        "    !pip uninstall -y click\n",
        "\n",
        "    print(f\"Installing 'click=={required_click_version}' for compatibility...\")\n",
        "    !pip install click=={required_click_version}\n",
        "\n",
        "    print(\"\\n--- 'click' setup complete. ---\")\n",
        "\n",
        "    # Display a prominent, styled HTML message in the cell output\n",
        "    html_message = \"\"\"\n",
        "    <div style=\"\n",
        "        background-color: #e8f5e9; /* Very light green, calming */\n",
        "        border: 2px solid #4caf50; /* Green border */\n",
        "        padding: 15px;\n",
        "        margin: 15px 0;\n",
        "        border-radius: 8px;\n",
        "        font-size: 1.1em; /* Slightly smaller font */\n",
        "        color: #000000; /* Black text */\n",
        "    \">\n",
        "        <h3>Runtime Setup Complete</h3>\n",
        "        <p>Package versions have been updated. For changes to take effect, you <strong>MUST restart the Colab runtime now.</strong></p>\n",
        "        <p>Go to the menu: <strong><code>Runtime</code> &gt; <code>Restart runtime</code></strong>.</p>\n",
        "        <p>After reconnecting, simply click <strong><code>Run All</code></strong> from the top to continue.</p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    display(HTML(html_message))\n",
        "\n",
        "    # Stop the Python cell execution gracefully.\n",
        "    raise SystemExit(\"Please restart the Colab runtime to apply changes.\")\n",
        "\n",
        "else:\n",
        "    print(f\"--- 'click' is already at the correct version ({required_click_version}). No action needed. ---\")"
      ],
      "metadata": {
        "id": "U4Gnr_pqa1QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8_G2ePO11rQ"
      },
      "source": [
        "## File downloading script\n",
        "\n",
        "grequests contains a script to download files from the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzkCTNNChWAJ"
      },
      "outputs": [],
      "source": [
        "!curl -L https://raw.githubusercontent.com/uCertifyLLC/Building-Business-Ready-Generative-AI-Systems/main/commons/grequests.py --output grequests.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmmBBZ7oa17b"
      },
      "source": [
        "## OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_PuE5rjhWAK"
      },
      "outputs": [],
      "source": [
        "from grequests import download\n",
        "download(\"commons\",\"requirements01.py\")\n",
        "download(\"commons\",\"openai_setup.py\")\n",
        "download(\"commons\",\"reason.py\")\n",
        "download(\"commons\",\"machine_learning.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kNLfjTfAnFR"
      },
      "source": [
        "### Installing OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7i8j5vnpatH"
      },
      "outputs": [],
      "source": [
        "# Run the setup script to install and import dependencies\n",
        "%run requirements01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O03SZzGGAreV"
      },
      "source": [
        "#### Initializing the OpenAI API key\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDn09vPbAXPT"
      },
      "outputs": [],
      "source": [
        "google_secrets=True #activates Google secrets in Google Colab\n",
        "if google_secrets==True:\n",
        "  import openai_setup\n",
        "  openai_setup.initialize_openai_api()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3398f_cetsD"
      },
      "outputs": [],
      "source": [
        "if google_secrets==False: # Uncomment the code and choose any method you wish to initialize the API_KEY\n",
        "  import os\n",
        "  #API_KEY=[YOUR API_KEY]\n",
        "  #os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "  #openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "  #print(\"OpenAI API key initialized successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NL93eSL-mLi"
      },
      "source": [
        "#### Importing the API call function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lMhv09G0kzr"
      },
      "outputs": [],
      "source": [
        "# Import the function from the custom OpenAI API file\n",
        "import os\n",
        "import reason\n",
        "from reason import make_openai_api_call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGpMI-5iLFMm"
      },
      "source": [
        "## Installing gtts\n",
        "\n",
        "gTTS (Google Text-to-Speech) is a Python library and CLI tool that interfaces with Google Translate's text-to-speech API. It allows users to convert text into spoken words, supporting multiple languages and accents, and can save the output as MP3 files.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use_gtts activates Google TTS in Google Colab if use_gtts is True and deactivates if False\n",
        "if use_gtts:\n",
        " !pip install gTTS==2.5.4\n",
        " from gtts import gTTS\n",
        " from IPython.display import Audio\n",
        "\n",
        "def text_to_speech(text):\n",
        "    # Convert text to speech and save as an MP3 file\n",
        "    if use_gtts:\n",
        "      if not isinstance(text, str):\n",
        "            text = str(text) # Making sure the text is a string not a list\n",
        "      tts = gTTS(text)\n",
        "      tts.save(\"response.mp3\")"
      ],
      "metadata": {
        "id": "yj7SKn8Ya_R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWL8u0g8Em1m"
      },
      "source": [
        "## Machine learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edZKk7Q2FzVi"
      },
      "outputs": [],
      "source": [
        "# Import the function from the custom OpenAI API file\n",
        "import os\n",
        "import machine_learning\n",
        "from machine_learning import ml_agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeaIj1Y6GNva"
      },
      "source": [
        "## Web search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGVnBoLNF2EC"
      },
      "outputs": [],
      "source": [
        "download(\"commons\",\"web_search.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL3Og0uYFPqo"
      },
      "outputs": [],
      "source": [
        "# Import the function from the custom OpenAI API file\n",
        "import os\n",
        "import web_search\n",
        "from web_search import search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjBYt-f6S4d"
      },
      "source": [
        "## Chain of Thought(COT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SLXIJHF6kTQ"
      },
      "outputs": [],
      "source": [
        "# Import the function from the custom OpenAI API file\n",
        "import os\n",
        "import reason\n",
        "from reason import chain_of_thought_reasoning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QGI1D8FVrT6"
      },
      "source": [
        "## Installing Pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3ufJsT54EHe"
      },
      "outputs": [],
      "source": [
        "download(\"commons\",\"requirements02.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Z2abuU9OkVFL"
      },
      "outputs": [],
      "source": [
        "# Run the setup script to install and import dependencies\n",
        "%run requirements02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tum9Jd1odcNK"
      },
      "source": [
        "### Initializing the Pinecone API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eIyjdd25LjH"
      },
      "outputs": [],
      "source": [
        "download(\"commons\",\"pinecone_setup.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zPS_mgsdXKj"
      },
      "outputs": [],
      "source": [
        "if google_secrets==True:\n",
        "  import pinecone_setup\n",
        "  pinecone_setup.initialize_pinecone_api()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-dJTlEn_FZZ"
      },
      "outputs": [],
      "source": [
        "if google_secrets==False: # Uncomment the code and choose any method you wish to initialize the Pinecone API key\n",
        "  import os\n",
        "  #PINECONE_API_KEY=[YOUR PINECONE_API_KEY]\n",
        "  #os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
        "  #openai.api_key = os.getenv(\"PINECONE_API_KEY\")\n",
        "  #print(\"OpenAI API key initialized successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XswfiN5Z1OvT"
      },
      "source": [
        "##  The Pinecone index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKCvBbZPTIjH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "# Retrieve the API key from environment variables\n",
        "api_key = os.environ.get('PINECONE_API_KEY')\n",
        "if not api_key:\n",
        "    raise ValueError(\"PINECONE_API_KEY is not set in the environment!\")\n",
        "\n",
        "# Initialize the Pinecone client\n",
        "pc = Pinecone(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P---PNLpXeQs"
      },
      "outputs": [],
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "index_name = 'genai-v1'\n",
        "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
        "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
        "\n",
        "spec = ServerlessSpec(cloud=cloud, region=region)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO7AYljM0gq1"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pinecone\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    # if does not exist, create index\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension=1536,  # dimension of the embedding model\n",
        "        metric='cosine',\n",
        "        spec=spec\n",
        "    )\n",
        "    # wait for index to be initialized\n",
        "    time.sleep(1)\n",
        "\n",
        "# connect to index\n",
        "index = pc.Index(index_name)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iIIeZB7RUDZ"
      },
      "source": [
        "## Querying functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS2HWdO76iQh"
      },
      "outputs": [],
      "source": [
        "def display_results(query_results):\n",
        "  for match in query_results['matches']:\n",
        "    print(f\"ID: {match['id']}, Score: {match['score']}\")\n",
        "    if 'metadata' in match and 'text' in match['metadata']:\n",
        "        text=match['metadata']['text']\n",
        "        #print(f\"Text: {match['metadata']['text']}\")\n",
        "        target_id = query_results['matches'][0]['id']  # Get the ID from the first match\n",
        "                #print(f\"Target ID: {target_id}\")\n",
        "    else:\n",
        "        print(\"No metadata available.\")\n",
        "  return text, target_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT6wytGz5hTS"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "client = openai.OpenAI()\n",
        "embedding_model = \"text-embedding-3-small\"\n",
        "def get_embedding(text, model=embedding_model):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    response = client.embeddings.create(input=[text], model=model)\n",
        "    embedding = response.data[0].embedding\n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FxS2Q0nnZAq"
      },
      "outputs": [],
      "source": [
        "def get_query_results(query_text, namespace):\n",
        "    # Generate the query vector from the query text\n",
        "    query_vector = get_embedding(query_text)  # Replace with your method to generate embeddings\n",
        "\n",
        "    # Perform the query\n",
        "    query_results = index.query(\n",
        "        vector=query_vector,\n",
        "        namespace=namespace,\n",
        "        top_k=1,  # Adjust as needed\n",
        "        include_metadata=True\n",
        "    )\n",
        "    # Return the results\n",
        "    return query_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-k5GxQGZSjlY"
      },
      "outputs": [],
      "source": [
        "def query_vector_store(query_text, namespace):\n",
        "    print(\"Querying vector store...\")\n",
        "\n",
        "    # Retrieve query results\n",
        "    query_results = get_query_results(query_text, namespace)\n",
        "\n",
        "    # Process and display the results\n",
        "    print(\"Processed query results:\")\n",
        "    text, target_id = display_results(query_results)\n",
        "\n",
        "    return text, target_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "022ADwbe3WmV"
      },
      "source": [
        "# The dataset: hotel reviews\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWG2zCZDGimF"
      },
      "source": [
        "Strategic Storytelling: Leveraging Memory in Marketing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBmqSgyQ5hIi"
      },
      "source": [
        "## Download and process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqULBYA65SxH"
      },
      "outputs": [],
      "source": [
        "download(\"Chapter06\",\"hotel_reviews.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvBGTZgb5q61"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Load the CSV file into a Pandas DataFrame\n",
        "dfta = pd.read_csv('/content/hotel_reviews.csv',sep=',')\n",
        "# display the DataFrame\n",
        "dfta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v027Jf0a6BPG"
      },
      "source": [
        "### Select index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keY1soDi6EZO"
      },
      "outputs": [],
      "source": [
        "index_number = 0  # Specify the index number\n",
        "\n",
        "try:\n",
        "    # Retrieve the row at the specified index\n",
        "    row = dfta.iloc[index_number]\n",
        "\n",
        "    # Extract the desired fields\n",
        "    review = row['Review']\n",
        "    rating = row['Rating']\n",
        "\n",
        "    # Display the results\n",
        "    print(f\"Review: {review}\")\n",
        "    print(f\"Rating: {rating}\")\n",
        "except IndexError:\n",
        "    print(f\"Error: Index {index_number} is out of bounds for the DataFrame.\")\n",
        "except KeyError as e:\n",
        "    print(f\"Error: Column '{e}' not found in the DataFrame.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pqFSbGecoZ3"
      },
      "source": [
        "# The functions of the consumer memory agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA8xaVeCsHTi"
      },
      "source": [
        "## Prompts and messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZsjrrG9EMzr"
      },
      "outputs": [],
      "source": [
        "from reason import memory_reasoning_thread # import memory reasoning\n",
        "download(\"commons\",\"cot_messages_c6.py\") # downloaded messages and prompts\n",
        "from cot_messages_c6 import system_message_s1, generation,imcontent4,imcontent4b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNEo5B1JAyUO"
      },
      "source": [
        "## Step 1 : Memory and sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmxJkvCe-4Bu"
      },
      "source": [
        "### The complex system message for step 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DG1fErLS67ey"
      },
      "outputs": [],
      "source": [
        "print(system_message_s1) # Print to verify"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the analysis"
      ],
      "metadata": {
        "id": "yvM6TQXvz1ns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbplKfEWhnJi"
      },
      "outputs": [],
      "source": [
        "# Step 1 : Memory and sentiment analysis\n",
        "mrole= system_message_s1\n",
        "user_text=review\n",
        "retres=reason.make_openai_reasoning_call(user_text, mrole)\n",
        "\n",
        "# Print the generated output (memory analysis)\n",
        "print(retres)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNBDCotShcL0"
      },
      "source": [
        "## Step 2: Extract scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EepkowkRmSMf"
      },
      "outputs": [],
      "source": [
        "def extract(tasks_response):\n",
        "  umessage = \"\"\"\n",
        "  1) Read the following text analysis that returns detailed memory tags for each part of the text\n",
        "  2) Then return the list of memory tags with absolutely no other text\n",
        "  3) Use no formatting, no hashtags, no markdown. Just answer in plain text\n",
        "  4) Also provide the sentiment analysis score for each tag in this format(no brackets) : memory tag sentiment Score\n",
        "  \"\"\"\n",
        "  umessage+=retres\n",
        "  mrole = \"system\"\n",
        "  mcontent = \"You are a marketing expert specialized in the psychological analysis of content\"\n",
        "  user_role = \"user\"\n",
        "  task_response = reason.make_openai_api_call(umessage,mrole,mcontent,user_role)\n",
        "  return task_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Mdsl8HKa5zL"
      },
      "outputs": [],
      "source": [
        "# Step 2: Extract scores\n",
        "task_response=extract(retres)\n",
        "print(task_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d1GU66kPhIV"
      },
      "source": [
        "## Step 3: Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-WoQLq4h84t"
      },
      "outputs": [],
      "source": [
        "# Step 3 : Statistics\n",
        "import re\n",
        "\n",
        "# Input text\n",
        "text=task_response\n",
        "\n",
        "# Regular expression to extract sentiment scores\n",
        "pattern = r\"(\\d+\\.\\d+)\"\n",
        "scores = [float(match) for match in re.findall(pattern, text)]\n",
        "\n",
        "# Output the extracted scores\n",
        "print(\"Extracted sentiment scores:\", scores)\n",
        "\n",
        "# Optional: calculate the overall score and scaled rating\n",
        "if scores:\n",
        "    overall_score = sum(scores) / len(scores)\n",
        "    scaled_rating = overall_score * 5\n",
        "    print(\"Overall score (0–1):\", round(overall_score, 2))\n",
        "    print(\"Scaled rating (0–5):\", round(scaled_rating, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv4gd6_pNMwJ"
      },
      "source": [
        "## Step 4: Content creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPDfsAHVznjr"
      },
      "source": [
        "### Generation Message for step 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generation)"
      ],
      "metadata": {
        "id": "OnLaZ4OPE0MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh5HWLETlotj"
      },
      "source": [
        "### The content creation call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EsTGiOBNS4g"
      },
      "outputs": [],
      "source": [
        "#Step 4: Creating content\n",
        "ugeneration=generation + \"The advanced memory analysis of each segment of a text with a sentiment score:\" + retres + \" the scaled overall rating: \"+ str(scaled_rating)+ \" and the list of memory tags of the text \"+ task_response\n",
        "mrole4 = \"system\"\n",
        "mcontent4 = imcontent4\n",
        "user_role = \"user\"\n",
        "pre_creation_response = make_openai_api_call(ugeneration,mrole4,mcontent4,user_role)\n",
        "print(pre_creation_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUaUENv3taIZ"
      },
      "outputs": [],
      "source": [
        "  umessage4b=\"Clean and simplify the following text for use as a DALL-E prompt. Focus on converting the detailed analysis into a concise visual description suitable for generating an engaging promotional image\" + pre_creation_response\n",
        "  mrole4b = \"system\"\n",
        "  mcontent4b = imcontent4b\n",
        "  user_role4b = \"user\"\n",
        "  creation_response = make_openai_api_call(umessage4b,mrole4b,mcontent4b,user_role4b)\n",
        "print(creation_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAC82qrqQoTR"
      },
      "source": [
        "## Step 5 Image creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkXzWbzhQtmI"
      },
      "outputs": [],
      "source": [
        "# Step 5: Creating an image\n",
        "import requests\n",
        "prompt=creation_response\n",
        "image_url = reason.generate_image(prompt)\n",
        "save_path = \"c_image.png\"\n",
        "image_data = requests.get(image_url).content\n",
        "with open(save_path, \"wb\") as file:\n",
        "  file.write(image_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_B9lwFRURvA"
      },
      "source": [
        "## Step 6 Message creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxK0sbXVPi5F"
      },
      "outputs": [],
      "source": [
        "# Step 6: Creating a customer message\n",
        "\n",
        "umessage6 = \"\"\"\n",
        "1) Read the following text carefully\n",
        "2) Then sum it up in a paragraphs without numbering the lines\n",
        "3 They output should be a text to send to a customer\n",
        "\"\"\"\n",
        "umessage6b=creation_response\n",
        "mrole6 = \"system\"\n",
        "mcontent6 = \"You are an expert in summarization for texts to send to a customer.Begin with Dear Customer and finish with Best regards\"\n",
        "user_role6b = \"user\"\n",
        "process_response = make_openai_api_call(umessage6b,mrole6,mcontent6,user_role6b)\n",
        "print(process_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display outputs"
      ],
      "metadata": {
        "id": "ZsK139jO4RbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import Image, display\n",
        "import textwrap\n",
        "# Set the desired width for each line\n",
        "line_width = 70\n",
        "# Wrap the text to the specified width\n",
        "wrapped_message = textwrap.fill(process_response, width=line_width)\n",
        "print(wrapped_message)\n",
        "\n",
        "# Define the image path\n",
        "image_path = \"/content/c_image.png\"\n",
        "\n",
        "# Check if the image file exists\n",
        "if os.path.exists(image_path):\n",
        "    # Display the image\n",
        "    display(Image(filename=image_path))\n",
        "else:\n",
        "    print(f\"Image file {image_path} not found.\")"
      ],
      "metadata": {
        "id": "hhA1aqDj4BnG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JBmqSgyQ5hIi"
      ],
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNuv6xx08GGp20nXYnJO0YH"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}