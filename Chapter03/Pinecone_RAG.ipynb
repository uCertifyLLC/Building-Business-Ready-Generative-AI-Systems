{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFLLl1Agum8O"
      },
      "source": [
        "# Pinecone RAG: upserting data\n",
        "\n",
        "copyright 2025, Denis Rothman\n",
        "\n",
        "# Pinecone vector store\n",
        "\n",
        "copyright 2024, Denis Rothman\n",
        "\n",
        "The goal of this notebook is to upsert *classical RAG data* to a Pinecone index for retrieval to provide instructions to a generative AI model.\n",
        "\n",
        "The notebook contains the following sections:\n",
        "* **Setting up the environment** with a file downloading script, OpenAI, and Pinecone.\n",
        "* **Processing the Data: loading and chunking** to load the instruction scenarios and chunk them.\n",
        "* **Embedding the chunked data**\n",
        "* **The Pinecone index** to create or connect to a Pinecone index and upsert the chunked and embedded data (text data)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the environment"
      ],
      "metadata": {
        "id": "vub82Rjxa17a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook was developed in Google Colab. Colab includes many pre-installed libraries and sets `/content/` as the default directory, meaning you can access files directly by their filename if you wish (e.g., `filename` instead of needing to specify `/content/filename`). This differs from local environments, where you'll often need to install libraries or specify full file paths."
      ],
      "metadata": {
        "id": "Nb0mHg3p4yBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File downloading script\n",
        "\n",
        "grequests contains a script to download files from the repository"
      ],
      "metadata": {
        "id": "S8_G2ePO11rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L https://raw.githubusercontent.com/uCertifyLLC/Building-Business-Ready-Generative-AI-Systems/main/commons/grequests.py --output grequests.py"
      ],
      "metadata": {
        "id": "vzkCTNNChWAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI"
      ],
      "metadata": {
        "id": "jmmBBZ7oa17b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from grequests import download\n",
        "download(\"commons\",\"requirements01.py\")\n",
        "download(\"commons\",\"openai_setup.py\")\n",
        "download(\"commons\",\"openai_api.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdea2295-fce8-494f-9152-e07545abcdd7",
        "id": "G_PuE5rjhWAK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'requirements01.py' successfully.\n",
            "Downloaded 'openai_setup.py' successfully.\n",
            "Downloaded 'openai_api.py' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing OpenAI"
      ],
      "metadata": {
        "id": "9kNLfjTfAnFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the setup script to install and import dependencies\n",
        "%run requirements01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7i8j5vnpatH",
        "outputId": "37d98a1e-ff37-4894-9004-7a1830a8724a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uninstalling 'openai'...\n",
            "Installing 'openai' version 1.57.1...\n",
            "'openai' version 1.57.1 is installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initializing the OpenAI API key\n",
        "\n"
      ],
      "metadata": {
        "id": "O03SZzGGAreV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_secrets=True #activates Google secrets in Google Colab\n",
        "if google_secrets==True:\n",
        "  import openai_setup\n",
        "  openai_setup.initialize_openai_api()"
      ],
      "metadata": {
        "id": "pDn09vPbAXPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "379604f2-d9d0-48bd-c038-68f2238623cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if google_secrets==False: # Uncomment the code and choose any method you wish to initialize the API_KEY\n",
        "  import os\n",
        "  #API_KEY=[YOUR API_KEY]\n",
        "  #os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "  #openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "  #print(\"OpenAI API key initialized successfully.\")"
      ],
      "metadata": {
        "id": "C3398f_cetsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NL93eSL-mLi"
      },
      "source": [
        "#### Importing the API call function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the function from the custom OpenAI API file\n",
        "import openai_api\n",
        "from openai_api import make_openai_api_call"
      ],
      "metadata": {
        "id": "0lMhv09G0kzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QGI1D8FVrT6"
      },
      "source": [
        "## Installing Pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download(\"commons\",\"requirements02.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3ufJsT54EHe",
        "outputId": "3c31d55b-e071-4bfc-be72-4750229b400a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'requirements02.py' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z2abuU9OkVFL",
        "outputId": "f700771f-df93-4909-fcf6-44553b5b6a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uninstalling 'pinecone-client'...\n",
            "Installing 'pinecone-client' version 5.0.1...\n",
            "'pinecone-client' version 5.0.1 is installed.\n"
          ]
        }
      ],
      "source": [
        "# Run the setup script to install and import dependencies\n",
        "%run requirements02"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the Pinecone API key"
      ],
      "metadata": {
        "id": "tum9Jd1odcNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download(\"commons\",\"pinecone_setup.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eIyjdd25LjH",
        "outputId": "4c449c84-c052-4f0c-e9f9-9c8fb3dd594a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'pinecone_setup.py' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if google_secrets==True:\n",
        "  import pinecone_setup\n",
        "  pinecone_setup.initialize_pinecone_api()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zPS_mgsdXKj",
        "outputId": "a8bc90ee-6914-45a3-be2f-38b9e6ec6a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PINECONE_API_KEY initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if google_secrets==False: # Uncomment the code and choose any method you wish to initialize the Pinecone API key\n",
        "  import os\n",
        "  #PINECONE_API_KEY=[YOUR PINECONE_API_KEY]\n",
        "  #os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
        "  #openai.api_key = os.getenv(\"PINECONE_API_KEY\")\n",
        "  #print(\"OpenAI API key initialized successfully.\")"
      ],
      "metadata": {
        "id": "D-dJTlEn_FZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVjOmtIiY1yf"
      },
      "source": [
        "# Processing data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download(\"Chapter03\",\"data01.txt\")"
      ],
      "metadata": {
        "id": "E5BjuWAZXXxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a827369-dd17-4f19-cb36-5bdde3decfa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'data01.txt' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8xEic_3fTg-"
      },
      "outputs": [],
      "source": [
        "# Load the CSV file\n",
        "file_path = '/content/data01.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA"
      ],
      "metadata": {
        "id": "Xw0Bi9x8fRR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read()\n",
        "    text\n",
        "except FileNotFoundError:\n",
        "    text = \"Error: File not found. Please check the file path.\"\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETKW9IzsP_s1",
        "outputId": "e59d52fe-543f-4666-b2a3-c01a09daedc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The CTO was explaing that a business-ready generative AI system (GenAISys) offers functionality similar to ChatGPT-like platforms. It combines generative AI models, RAG, memory retention, and a wide range of ML and non-AI functions managed by an AI controller. The controller orchestrates tasks dynamically rather than following the same set of instructions for each task.\n",
            "GenAISys relies on a generative AI model such as GPT-4o or any advanced LLM. The CTO said that we saw that getting access to the API is insufficient. Contextual awareness and memory retention are critical components of a GenAISys. Although they are seamlessly available in ChatGPT-like platforms, we have to build them into our systems.\n",
            "We defined memoryless, short-term, long-term memory, and cross-topic memory. For the hybrid travel marketing campaign, we will distinguish semantic memory(facts) from episodic memory(personal events in time, for example). The CTO said that the we will need to use episodic memories of past customer trips to make the semantic aspects of our trips more engaging. We could for example, merge geological semantic information with customer experiences to make our advertisements.Context awareness relies heavily on memory. However, we cannot increase context forever without going beyond the context windows of a generative AI Model. And even so, if the context is too large, the AI model will not be able to grasp the nuances we expect in complex texts.\n",
            "Advanced RAG can solve context window quantity and quality limitations by breaking content down into chunks, embedding them, and storing them in a vector store such as Pinecone. The retrieval process will target parts of document content, for example, to provide high-quality outputs. We took RAG further by introducing its orchestration role by storing generative AI scenarios that the AI controller will be able to retrieve and apply dynamically. The AI controller can then apply the instructions to trigger web searches, machine learning, and any functions we need for a project.\n",
            "We confirmed that GenAISys, no matter how powerful it is, cannot exist without human expertise. Human expertise is required to design, deploy, maintain, and implement evolutions across a Generative AI System's lifecycle.\n",
            "We realistically defined the implementation of business-ready GenAISys in three main forms, depending on resources and objectives: hybrid systems leveraging existing AI platforms, small-scale systems designed for focused use cases, or full-scale platforms capable of ChatGPT-grade performance.\n",
            "Finally, we built a hands-on exploration of contextual awareness and memory retention in Python using GPT-4o. We laid the groundwork for an AI Controller that will dynamically manage the different types of memory we need in GenAISys.\n",
            "We are ready to begin building a GenAISys AI controller.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIb_dIfe1fOq"
      },
      "source": [
        "## Chunking the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialize OpenAI Client\n",
        "client = OpenAI()\n",
        "\n",
        "# Function to chunk text using GPT-4o\n",
        "def chunk_text_with_gpt4o(text):\n",
        "    # Prepare the messages for GPT-4o\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are an assistant skilled at splitting long texts into meaningful, semantically coherent chunks of 50-100 words each.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Split the following text into meaningful chunks:\\n\\n{text}\"}\n",
        "    ]\n",
        "\n",
        "    # Make the GPT-4o API call\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",  # GPT-4o model\n",
        "        messages=messages,\n",
        "        temperature=0.2,  # Low randomness for consistent chunks\n",
        "        max_tokens=1024  # Sufficient tokens for the chunked response\n",
        "    )\n",
        "\n",
        "    # Extract and clean the response\n",
        "    chunked_text = response.choices[0].message.content\n",
        "    chunks = chunked_text.split(\"\\n\\n\")  # Assume GPT-4o separates chunks with double newlines\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Chunk the text\n",
        "chunks = chunk_text_with_gpt4o(text)\n",
        "\n",
        "# Display the chunks\n",
        "print(\"Chunks:\")\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"\\nChunk {i+1}:\")\n",
        "    print(chunk)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p0LxlcEdcwj",
        "outputId": "3c93c525-708c-49b4-d4aa-d35848b697b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunks:\n",
            "\n",
            "Chunk 1:\n",
            "The CTO was explaining that a business-ready generative AI system (GenAISys) offers functionality similar to ChatGPT-like platforms. It combines generative AI models, RAG, memory retention, and a wide range of ML and non-AI functions managed by an AI controller. The controller orchestrates tasks dynamically rather than following the same set of instructions for each task.\n",
            "\n",
            "Chunk 2:\n",
            "GenAISys relies on a generative AI model such as GPT-4o or any advanced LLM. The CTO said that getting access to the API is insufficient. Contextual awareness and memory retention are critical components of a GenAISys. Although they are seamlessly available in ChatGPT-like platforms, we have to build them into our systems.\n",
            "\n",
            "Chunk 3:\n",
            "We defined memoryless, short-term, long-term memory, and cross-topic memory. For the hybrid travel marketing campaign, we will distinguish semantic memory (facts) from episodic memory (personal events in time, for example). The CTO said that we will need to use episodic memories of past customer trips to make the semantic aspects of our trips more engaging.\n",
            "\n",
            "Chunk 4:\n",
            "We could, for example, merge geological semantic information with customer experiences to make our advertisements. Context awareness relies heavily on memory. However, we cannot increase context forever without going beyond the context windows of a generative AI Model. And even so, if the context is too large, the AI model will not be able to grasp the nuances we expect in complex texts.\n",
            "\n",
            "Chunk 5:\n",
            "Advanced RAG can solve context window quantity and quality limitations by breaking content down into chunks, embedding them, and storing them in a vector store such as Pinecone. The retrieval process will target parts of document content, for example, to provide high-quality outputs.\n",
            "\n",
            "Chunk 6:\n",
            "We took RAG further by introducing its orchestration role by storing generative AI scenarios that the AI controller will be able to retrieve and apply dynamically. The AI controller can then apply the instructions to trigger web searches, machine learning, and any functions we need for a project.\n",
            "\n",
            "Chunk 7:\n",
            "We confirmed that GenAISys, no matter how powerful it is, cannot exist without human expertise. Human expertise is required to design, deploy, maintain, and implement evolutions across a Generative AI System's lifecycle.\n",
            "\n",
            "Chunk 8:\n",
            "We realistically defined the implementation of business-ready GenAISys in three main forms, depending on resources and objectives: hybrid systems leveraging existing AI platforms, small-scale systems designed for focused use cases, or full-scale platforms capable of ChatGPT-grade performance.\n",
            "\n",
            "Chunk 9:\n",
            "Finally, we built a hands-on exploration of contextual awareness and memory retention in Python using GPT-4o. We laid the groundwork for an AI Controller that will dynamically manage the different types of memory we need in GenAISys. We are ready to begin building a GenAISys AI controller.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the length and content of the first 10 chunks\n",
        "for i in range(3):\n",
        "    print(len(chunks[i]))\n",
        "    print(chunks[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAllJxWjekv5",
        "outputId": "ef82ed50-d01d-4fbe-eda2-130fb42377fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "374\n",
            "The CTO was explaining that a business-ready generative AI system (GenAISys) offers functionality similar to ChatGPT-like platforms. It combines generative AI models, RAG, memory retention, and a wide range of ML and non-AI functions managed by an AI controller. The controller orchestrates tasks dynamically rather than following the same set of instructions for each task.\n",
            "324\n",
            "GenAISys relies on a generative AI model such as GPT-4o or any advanced LLM. The CTO said that getting access to the API is insufficient. Contextual awareness and memory retention are critical components of a GenAISys. Although they are seamlessly available in ChatGPT-like platforms, we have to build them into our systems.\n",
            "359\n",
            "We defined memoryless, short-term, long-term memory, and cross-topic memory. For the hybrid travel marketing campaign, we will distinguish semantic memory (facts) from episodic memory (personal events in time, for example). The CTO said that we will need to use episodic memories of past customer trips to make the semantic aspects of our trips more engaging.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, each line is treated as a separate chunk\n",
        "print(f\"Total number of chunks: {len(chunks)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX_dcEAuerP1",
        "outputId": "7e112b05-57e4-471f-8792-5b077ee71860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of chunks: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnpKzYzRpXfn"
      },
      "source": [
        "## Embedding\n",
        "\n",
        "**IMPORTANT NOTE**: OpenAI continually upgrades its models including the embedding models. As such, this section is updated when necessary for performance optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnNRM3aBlYea"
      },
      "source": [
        "## Initializing the embedding model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKl3UiJ3-pXE"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import time\n",
        "\n",
        "embedding_model=\"text-embedding-3-small\"\n",
        "#embedding_model=\"text-embedding-3-large\"\n",
        "#embedding_model=\"text-embedding-ada-002\"\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = openai.OpenAI()\n",
        "\n",
        "def get_embedding(texts, model=\"text-embedding-3-small\"):\n",
        "    texts = [text.replace(\"\\n\", \" \") for text in texts]  # Clean input texts\n",
        "    response = client.embeddings.create(input=texts, model=model)  # API call for batch\n",
        "    embeddings = [res.embedding for res in response.data]  # Extract embeddings\n",
        "    return embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCAEGyrve2pW"
      },
      "source": [
        "## Embedding the chunks\n",
        "\n",
        "    Parameters:\n",
        "        chunks (list): List of text chunks to be embedded.\n",
        "        embedding_model (str): Model to be used for embedding.\n",
        "        batch_size (int): Number of chunks to process per batch.\n",
        "        pause_time (int): Time to wait between batches (in seconds).\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_chunks(chunks, embedding_model=\"text-embedding-3-small\", batch_size=1000, pause_time=3):\n",
        "    start_time = time.time()  # Start timing the operation\n",
        "    embeddings = []  # Initialize an empty list to store the embeddings\n",
        "    counter = 1  # Batch counter\n",
        "\n",
        "    # Process chunks in batches\n",
        "    for i in range(0, len(chunks), batch_size):\n",
        "        chunk_batch = chunks[i:i + batch_size]  # Select a batch of chunks\n",
        "\n",
        "        # Get the embeddings for the current batch\n",
        "        current_embeddings = get_embedding(chunk_batch, model=embedding_model)\n",
        "\n",
        "        # Append the embeddings to the final list\n",
        "        embeddings.extend(current_embeddings)\n",
        "\n",
        "        # Print batch progress and pause\n",
        "        print(f\"Batch {counter} embedded.\")\n",
        "        counter += 1\n",
        "        time.sleep(pause_time)  # Optional: adjust or remove this depending on rate limits\n",
        "\n",
        "    # Print total response time\n",
        "    response_time = time.time() - start_time\n",
        "    print(f\"Total Response Time: {response_time:.2f} seconds\")\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "embeddings = embed_chunks(chunks)"
      ],
      "metadata": {
        "id": "wWhJBzn6Ggak",
        "outputId": "4dd161bc-aa2f-46fc-9832-2bcc5f0b0dda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 embedded.\n",
            "Total Response Time: 3.83 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1r5SVLu768D",
        "outputId": "d0248385-2604-44c9-f3af-bf165804a000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First embedding: [-0.011681988835334778, 0.007010514847934246, 0.04123054817318916, -0.007631615735590458, 0.00541811715811491, -0.0523575097322464, -0.006607459858059883, 0.02761918120086193, 0.020602058619260788, -0.02772490121424198, 0.0014181260485202074, -0.05756418779492378, -0.014192823320627213, -0.028649944812059402, -0.040279075503349304, -0.043080639094114304, -0.004602095577865839, -0.047970157116651535, 0.014708205126225948, -0.010492646135389805, 0.03055289387702942, 0.03639388829469681, -0.015818258747458458, 0.033513035625219345, 0.004816838074475527, -0.019016269594430923, 0.027698470279574394, 0.049740955233573914, -0.026297690346837044, 0.0001448479015380144, 0.04501001536846161, -0.017589056864380836, -0.012316305190324783, -0.01725868508219719, 0.018196944147348404, 0.015844687819480896, 0.03412092104554176, 0.018276233226060867, 0.017681561410427094, 0.039221879094839096, -0.008510407991707325, -0.01719260960817337, 0.014681775122880936, 0.018857689574360847, 0.005140603519976139, -0.004090017639100552, 0.01474784966558218, -0.02604660578072071, -0.021897122263908386, 0.026363763958215714, -0.031160779297351837, -0.019161632284522057, -0.0054841917008161545, -0.022822165861725807, -0.06586315482854843, 0.009587423875927925, -0.014827139675617218, 0.01846124231815338, -0.00521989306434989, 0.024738328531384468, -0.020628489553928375, -0.04368852451443672, -0.005857512820512056, 0.037715379148721695, -0.023601846769452095, -0.02413044311106205, -0.014602486044168472, 0.035389553755521774, -0.061951540410518646, 0.008569874800741673, -0.03906330093741417, -0.013941739685833454, -0.0454593226313591, -0.04033193364739418, -0.030341455712914467, 0.017932645976543427, -0.015646465122699738, 0.04310706630349159, 0.026614848524332047, -0.007717513013631105, 0.03044717386364937, -0.0019838898442685604, -0.03420021012425423, 0.0004959724610671401, 0.001970674842596054, -0.018157299607992172, -0.0008655771962366998, -0.023060034960508347, -0.04054337367415428, -0.010809804312884808, -0.016254350543022156, 0.030605753883719444, -0.034781668335199356, 0.0351252555847168, 0.01969023048877716, 0.010380319319665432, 0.028279926627874374, -0.007307850290089846, 0.018778400495648384, 0.035627420991659164, -0.0171265359967947, -0.04538003355264664, 0.016346855089068413, 0.0465429462492466, 0.03319587931036949, 0.0038587565068155527, -0.019254136830568314, -0.0015684457030147314, -0.010505860671401024, -0.01814408414065838, -0.04313349723815918, -0.02454010583460331, -0.001787317800335586, 0.031636517494916916, -0.025306571274995804, -0.04278990998864174, 0.02796277031302452, -0.006260568276047707, 0.009752610698342323, 0.03272014111280441, -0.01824980415403843, 0.025504793971776962, -0.021659253165125847, -0.004516198765486479, -0.038534704595804214, 0.0013198400847613811, -0.0069642625749111176, -0.02703772485256195, -0.04590862989425659, 0.0058376905508339405, -0.03472880646586418, 0.009118294343352318, -0.006577725987881422, -7.3946766860899515e-06, -0.028940673917531967, -0.039591897279024124, -0.0038092005997896194, -0.02785705029964447, -0.034675948321819305, -0.010254777036607265, 0.0003359480178914964, -0.022359643131494522, -0.018196944147348404, 0.04088696092367172, -0.05782848596572876, -0.038984011858701706, -0.03716035187244415, 0.019954528659582138, -0.035389553755521774, 0.0467543862760067, -0.04009406641125679, 0.00849058572202921, -0.015131082385778427, -0.046463657170534134, -0.014800709672272205, -0.0055370512418448925, -0.03356589376926422, 0.04849875345826149, -0.013406535610556602, -0.05597839877009392, 0.024421170353889465, 0.03203296288847923, -0.011483765207231045, 0.020311331376433372, -0.05037527158856392, 0.011047672480344772, 0.004364226944744587, 0.005087743978947401, -0.03961832821369171, 0.009534564800560474, -0.054022591561079025, -0.01440426241606474, -0.06263871490955353, 0.04141555726528168, 0.021685682237148285, -0.04080767184495926, -0.042393460869789124, 0.0011769537813961506, -0.012772219255566597, -0.025002626702189445, -0.02686593122780323, 0.03324873745441437, -0.01415317878127098, -0.017615487799048424, -0.03216511383652687, 0.00905882753431797, -0.0038719712756574154, -0.03531026467680931, 0.009732788428664207, 0.013836020603775978, -0.007406962104141712, 0.000936607422772795, 0.059149980545043945, 0.06422451138496399, 0.0351252555847168, -0.02716987393796444, 0.0657045766711235, -0.030632182955741882, 0.02372078038752079, -0.04056980088353157, 0.052383940666913986, -0.030130015686154366, 0.014509981498122215, -0.023086464032530785, 0.00551062123849988, -0.0019888454116880894, 0.04033193364739418, 0.02150067314505577, -0.0441642589867115, 0.00525623420253396, 0.03901044279336929, -0.048049446195364, 0.015289661474525928, 0.029337121173739433, -0.03541598469018936, -0.030605753883719444, -0.03975047916173935, 0.04141555726528168, 0.019029483199119568, 0.01457605604082346, -0.04012049362063408, 0.015117867849767208, 0.004982024431228638, 0.016809377819299698, -0.03552170470356941, 0.04440212994813919, 0.001141438609920442, -0.01992809772491455, 0.023985078558325768, -0.015091437846422195, 0.008047886192798615, 0.019399501383304596, -0.007023729849606752, -0.03708106279373169, -0.02662806212902069, 0.004516198765486479, 0.010261384770274162, -0.005067921709269285, 0.03369804471731186, 0.01814408414065838, -0.026205185800790787, 0.023707564920186996, 0.015976836904883385, -0.016941526904702187, 0.018368737772107124, 0.024090798571705818, -0.01328099425882101, -0.023297902196645737, 0.04067552089691162, 0.007638223469257355, 0.027566321194171906, -0.002889111638069153, 0.04963523894548416, -0.002254795515909791, -0.014721420593559742, -0.02012632228434086, 0.020364191383123398, 0.005276056472212076, 0.019848808646202087, -0.03155722841620445, 0.012283267453312874, 0.022267138585448265, -0.03578600287437439, -1.9151308151776902e-05, 0.005361953750252724, 0.015884332358837128, -0.01300348062068224, -0.012897761538624763, -0.007406962104141712, 0.006313427817076445, 0.005926891230046749, 0.007671260740607977, 0.009395807981491089, -0.009190976619720459, -0.029865717515349388, -0.0075523266568779945, -0.023522555828094482, 0.00885399617254734, -0.03221797198057175, 0.06882330030202866, -0.055766958743333817, -0.018025150522589684, 0.06073576956987381, 0.02662806212902069, -0.0078628771007061, 0.031874384731054306, 0.02727559395134449, -0.024870477616786957, -0.028253497555851936, -0.04789086803793907, 0.030632182955741882, -0.023628275841474533, 0.00032004882814362645, -0.00604252191260457, 0.025478364899754524, 0.024156872183084488, 0.06380163133144379, 0.09171154350042343, 0.029522130265831947, 0.01386245060712099, 0.040384795516729355, -0.026614848524332047, -0.014813924208283424, -0.020179182291030884, -0.01469499059021473, 0.042948488146066666, -0.05930855870246887, 0.015183942392468452, 0.03541598469018936, 0.013928525149822235, 0.020417051389813423, 0.0400676354765892, 0.0566655732691288, -0.016241135075688362, -0.036552466452121735, -0.039221879094839096, 0.03982976824045181, -0.054498326033353806, 0.03961832821369171, -0.028174208477139473, -0.013512254692614079, -0.0011496980441734195, -0.017337974160909653, -0.055185504257678986, -0.04918593168258667, -0.010875878855586052, 0.026813071221113205, 0.008246109820902348, 0.00471772626042366, 0.009666713885962963, 0.017311545088887215, 0.00554696237668395, -0.012891153804957867, -0.007089804392307997, 0.029654279351234436, 0.007426784839481115, -0.006680141668766737, 0.028147777542471886, 0.011985931545495987, -0.05571410059928894, -0.06163438409566879, 0.007684475742280483, -0.06818898767232895, -0.005973143503069878, -0.013968169689178467, 0.007823232561349869, -0.03065861389040947, 0.019425932317972183, 0.054286889731884, 0.01725868508219719, 0.01527644693851471, -0.05082457885146141, 0.004080106504261494, -0.01035388931632042, -0.020377404987812042, -0.0011026198044419289, -0.018751971423625946, -0.00012089586380170658, -0.03993548825383186, -0.00955438707023859, -0.025689803063869476, 0.03451737016439438, 0.03692248463630676, 0.012025577016174793, -0.002707406645640731, 0.03599743917584419, -0.05069243162870407, -0.0008664031629450619, 0.020483125001192093, -0.010155665688216686, 0.005398294422775507, -0.01100802794098854, -0.012937406077980995, -0.017285114154219627, -0.013809590600430965, -0.01503857783973217, -0.0038191117346286774, -0.016254350543022156, -0.03343374654650688, 0.030975770205259323, 0.01773442141711712, -0.011060887947678566, -0.011662166565656662, -0.03710749372839928, 0.010043338872492313, 0.014840354211628437, -0.010710692033171654, -0.0283327866345644, -0.054128311574459076, 0.042499180883169174, 0.03982976824045181, -0.0437413826584816, -0.03208582475781441, 0.01071729976683855, 0.025650158524513245, 0.016175061464309692, -0.011853782460093498, -0.06438308954238892, 0.020535985007882118, 0.03591815009713173, 0.03055289387702942, 0.003354937769472599, 0.0006743738777004182, 0.009177761152386665, 0.0009663410019129515, -0.028597084805369377, 0.021011721342802048, 0.038851864635944366, 0.01674330234527588, 0.002362166764214635, 0.04012049362063408, -0.006977477576583624, 0.0316629484295845, 0.00952134933322668, 0.03055289387702942, -7.504370842070784e-06, -0.020139537751674652, 0.038772571831941605, 0.038296837359666824, 0.06840042024850845, -0.026720566675066948, -0.039565470069646835, -0.016558293253183365, -0.048313744366168976, 0.0031781881116330624, -0.009534564800560474, 0.014523196034133434, 0.01777406595647335, -0.043080639094114304, -0.020430264994502068, -0.0065810298547148705, 0.02775133028626442, -0.03406806290149689, -0.05045456066727638, -0.010657832957804203, 0.09060148894786835, 0.03679033741354942, 0.008741669356822968, 0.0011224421905353665, -0.009309911169111729, -0.015461456030607224, 0.02044348046183586, -0.005857512820512056, -0.039803337305784225, -0.04707154259085655, 0.011219466105103493, -0.021897122263908386, -0.0192805677652359, -0.02259751223027706, -0.06374876946210861, -0.03581243008375168, 0.02419651672244072, 0.011629128828644753, 0.015355736017227173, -0.04699225351214409, 0.006267175544053316, 0.04908021166920662, -0.0007610967732034624, 0.035019535571336746, 0.020535985007882118, 0.035389553755521774, -0.020892787724733353, -0.03393591195344925, 0.03927474096417427, -0.008298969827592373, 0.0073144580237567425, 0.022161420434713364, 0.012441846542060375, -0.011041064746677876, 0.0005091873463243246, -0.05396972969174385, 0.00418582558631897, -0.005854209419339895, 0.0024464118760079145, -0.0029204972088336945, 0.010908915661275387, 0.01992809772491455, 0.008146997541189194, -0.016227921470999718, -0.004915949888527393, -0.021553533151745796, 0.01678294688463211, -0.006931225303560495, 0.04466642811894417, 0.019055914133787155, 0.06152866408228874, -0.0020863052923232317, -0.04160056635737419, 0.030579322949051857, -0.00674952007830143, -0.03568028286099434, -0.01626756601035595, 0.0829368308186531, -0.014509981498122215, 0.04548575356602669, -0.0036737476475536823, -0.0023076552897691727, -0.036420319229364395, -0.08288397639989853, 0.005857512820512056, 0.014959288761019707, 0.027777761220932007, -0.000476563029224053, 0.011510195210576057, -0.008384866639971733, -0.03227083384990692, 0.00895310752093792, 0.05328255519270897, 0.028702804818749428, -0.027487032115459442, -0.0011802575318142772, -0.020324546843767166, -0.02761918120086193, 0.03948618099093437, 0.006009484641253948, 0.01777406595647335, -0.0070831966586411, 0.051696766167879105, 0.018923765048384666, -0.019095558673143387, -0.015937192365527153, 0.005259538069367409, -0.026258043944835663, -0.0197166595607996, -0.013353675603866577, -0.02994500659406185, -0.01589754782617092, -0.013426357880234718, -0.04059623181819916, -0.040279075503349304, 0.03660532832145691, 0.010274600237607956, 0.016624368727207184, -0.00020689607481472194, -0.08626699447631836, -0.03266727924346924, 0.006709875538945198, 0.026059821248054504, -0.047520849853754044, 0.01934664137661457, -0.04360923543572426, 0.012058613821864128, 0.03179509565234184, -0.003881882643327117, -0.014800709672272205, 0.017787281423807144, -0.022372858598828316, -0.03507239744067192, 0.0055899107828736305, 0.05222536250948906, 0.0568770132958889, -0.023192184045910835, 0.04508930444717407, -0.010413356125354767, 0.011966109275817871, -0.014179608784615993, 0.005464368965476751, 0.0008589697536081076, 0.02615232579410076, 0.005226500798016787, -0.025200851261615753, -0.010737122036516666, 0.006653712131083012, -0.03272014111280441, -0.014100318774580956, 0.025174422189593315, 0.00018376996740698814, 0.01498571876436472, 0.01469499059021473, -0.013677441515028477, -0.0263901948928833, 0.039116162806749344, -0.0014362965011969209, 0.006257264409214258, 0.001701420871540904, 0.014232467859983444, 0.024870477616786957, 0.0014866783749312162, 0.004076802637428045, 0.03837612643837929, -0.004000816959887743, -0.031425077468156815, -0.003997513093054295, -0.019320212304592133, -0.022822165861725807, -0.0012578951427713037, -0.010763552039861679, 0.050401702523231506, 0.03219154477119446, 0.046807244420051575, -0.002444760175421834, -0.018263017758727074, 0.017747636884450912, -0.016967955976724625, -0.010902308858931065, -0.03089648112654686, 0.01941271685063839, 0.007677868008613586, -0.043292075395584106, 0.057194169610738754, 0.018434813246130943, -0.025623729452490807, -0.042948488146066666, 0.008695417083799839, -0.031398650258779526, -0.03272014111280441, -0.03338088467717171, 0.013571722432971, 0.01889733411371708, -0.03335445746779442, 0.01411353424191475, 0.005827779415994883, -0.019743090495467186, -0.05840994417667389, -0.02738131210207939, -0.01753619872033596, -0.01399459969252348, 0.011060887947678566, 0.07157200574874878, 0.0018748666625469923, 0.008721847087144852, -0.01883126050233841, 0.010082983411848545, -0.009587423875927925, -0.012970443814992905, 0.01485356967896223, 0.024051154032349586, -0.027222733944654465, -0.06152866408228874, 0.009111686609685421, 0.02915211208164692, 0.020998507738113403, -0.0007788543007336557, 0.022716445848345757, -0.02029811590909958, -0.033618755638599396, -0.014219253323972225, -0.0010381970787420869, 0.02761918120086193, -0.03412092104554176, -0.0206813495606184, 0.023800069466233253, -0.007050159387290478, -0.013135629706084728, 0.023112893104553223, 0.024183303117752075, -0.03184795752167702, 0.004684688989073038, 0.007684475742280483, 0.006234138272702694, -0.032561562955379486, -0.05756418779492378, 0.024090798571705818, -0.012018969282507896, 0.009237228892743587, -0.02587481215596199, 0.0021986321080476046, -0.03837612643837929, 0.03681676462292671, 0.007499466650187969, -0.02245214767754078, -0.03927474096417427, 0.001609742408618331, 0.009785647504031658, -0.005943410098552704, 0.048789482563734055, 0.012474884279072285, 0.01317527424544096, 0.005431331694126129, 0.019571295008063316, -0.03174223750829697, 0.012844901531934738, -0.0009589075925759971, 0.01054550614207983, 0.01052568294107914, -0.02440795674920082, -0.006396020762622356, -0.04022621363401413, 0.018064795061945915, -0.011576269753277302, -0.026020176708698273, 0.029759999364614487, -0.02214820496737957, 0.02512156218290329, 0.041785575449466705, -0.03520454466342926, 0.01947879046201706, -0.007499466650187969, 0.015527530573308468, -0.023919004946947098, -0.01835552230477333, 0.02809491939842701, -0.0022977441549301147, 0.007261598017066717, 0.009805469773709774, -0.02772490121424198, 0.017615487799048424, 0.0370546355843544, -0.02395864948630333, -0.003911616280674934, -0.04152127727866173, 0.02820063754916191, 0.00866237934678793, -0.008629342541098595, -0.025280140340328217, -0.029918577522039413, -0.01220397837460041, -0.004572362173348665, 0.02716987393796444, 0.016293995082378387, -0.052753958851099014, -0.01684902235865593, 0.009990478865802288, 0.011695203371345997, 0.012706144712865353, 0.00857648253440857, 0.0130893774330616, 0.0024001598358154297, 0.021553533151745796, -0.03739822283387184, -0.04054337367415428, 0.0218706913292408, -0.018223373219370842, -0.010756944306194782, -0.038296837359666824, -0.03552170470356941, -0.03708106279373169, 0.021421384066343307, -0.057088453322649, 0.010677655227482319, 0.006300212815403938, -0.020258471369743347, 0.010453001596033573, -0.0019244226859882474, 0.029337121173739433, -0.0028461632318794727, -0.023575415834784508, -0.035838861018419266, -0.03380376473069191, -0.018738755956292152, -0.003660532645881176, -0.017893001437187195, -0.026601633056998253, -0.0018963409820571542, -0.013836020603775978, 0.01514429785311222, 0.02796277031302452, 0.03250870108604431, 0.05661271512508392, -0.01962415501475334, -0.016082556918263435, 0.011047672480344772, -0.009342947974801064, 0.015672894194722176, 0.0028412076644599438, 0.015699325129389763, 0.017628703266382217, -0.014549626037478447, -0.017615487799048424, 0.019703444093465805, 0.004836660344153643, -0.005847601685672998, 0.0041924333199858665, 0.0214345995336771, 0.0058773355558514595, -0.03784753009676933, 0.0512738861143589, 0.019941313192248344, -0.010532290674746037, 0.019809164106845856, -0.001298365881666541, 0.02464582398533821, -0.007895913906395435, -0.01678294688463211, 0.0062473532743752, -0.015210372395813465, 0.04310706630349159, -0.04186486452817917, 0.02960141934454441, 0.02389257401227951, 0.007585363928228617, -0.001157131395302713, -0.0006351420888677239, 0.025848383083939552, -0.02775133028626442, -0.001949200639501214, 0.007347495295107365, 0.00787609163671732, -0.02587481215596199, -0.02290145494043827, -0.008338614366948605, 0.03464951738715172, 0.014774279668927193, 0.014338187873363495, -0.005408205557614565, 0.009303303435444832, -0.004063587635755539, -0.05328255519270897, -0.023866144940257072, -0.009897974319756031, -0.02341683767735958, 0.020417051389813423, -0.013109199702739716, 0.05399616062641144, 0.023403622210025787, 0.04033193364739418, -0.03287871927022934, 0.010657832957804203, -0.022227494046092033, -2.1009656848036684e-05, 0.023839714005589485, 0.019531650468707085, -0.01192646473646164, -0.030737902969121933, -0.030685042962431908, 0.051115307956933975, -0.02413044311106205, -0.0030658612959086895, -0.013571722432971, -0.011483765207231045, 0.005566784646362066, -0.018963409587740898, -0.014932858757674694, -0.002988223684951663, 0.03285228833556175, -0.00902578979730606, 0.0032013142481446266, -0.013598152436316013, -0.007955381646752357, 0.005705541465431452, 0.05492120608687401, 0.0030757724307477474, 0.00670657167211175, 0.011278933845460415, 0.018672680482268333, 0.01592397876083851, 0.0024216340389102697, -0.014972503297030926, -0.02331111766397953, 0.059625715017318726, -0.010082983411848545, -0.022571083158254623, 0.02447403036057949, 0.03161008656024933, -0.017100105062127113, -0.010261384770274162, -0.011662166565656662, 0.03348660469055176, 0.01695474237203598, 0.016901882365345955, -0.025544438511133194, -0.0040074242278933525, 0.03203296288847923, 0.0009878152050077915, -0.0026413321029394865, 0.04064909368753433, 0.014311757870018482, -0.00699069257825613, 0.022888239473104477, 0.04836660623550415, -0.008094138465821743, 0.013300816528499126, 0.002978312550112605, 0.032587990164756775, 0.03195367380976677, -0.006884973030537367, -0.03531026467680931, -0.029204972088336945, 0.038058966398239136, -0.035733141005039215, 0.02846493571996689, 0.01279864925891161, -0.006729697808623314, 0.0441642589867115, 0.059731435030698776, 0.005127388518303633, -0.016730088740587234, -0.018619822338223457, -0.006865150760859251, -0.023866144940257072, 0.01794586144387722, -0.04741512984037399, 0.011734848842024803, -0.005649378057569265, -0.003908312413841486, -0.01370387151837349, 0.01238898653537035, 0.02775133028626442, -0.04117769002914429, 0.021064581349492073, -0.0056824153289198875, 0.009045612066984177, 0.027196304872632027, -0.025967316702008247, 0.013532077893614769, 0.005243019200861454, -0.0030443870928138494, 0.010096198879182339, -0.006055736914277077, -0.03332802653312683, -0.006217619404196739, -1.5150698345678393e-05, -0.001701420871540904, -0.018064795061945915, 0.019980957731604576, 0.029442841187119484, -0.009997086599469185, 0.019439145922660828, 0.01958451047539711, -0.02697165124118328, -0.00816681981086731, -0.009693142957985401, 0.035495273768901825, 0.012369164265692234, -0.009488312527537346, -0.018104439601302147, -0.002880852436646819, 0.014708205126225948, 0.00567250419408083, -0.04519502446055412, 2.988843152706977e-05, -0.019531650468707085, 0.010789982043206692, -0.01671687327325344, -0.010651225224137306, -0.007816624827682972, -0.012018969282507896, -0.026918791234493256, -0.007228560745716095, 0.00907204207032919, 0.026945220306515694, -0.010776766575872898, -0.007413569837808609, -0.013941739685833454, -0.01883126050233841, -0.020892787724733353, 0.006574422586709261, 0.020628489553928375, -0.019835593178868294, -0.014972503297030926, -0.008279146626591682, -0.022438932210206985, -0.05185534432530403, 0.0007020425982773304, -0.004248596727848053, -0.02320539765059948, 0.00955438707023859, 0.028755664825439453, -0.023126108571887016, 0.028967102989554405, 0.057299889624118805, -0.0007251686765812337, 0.05373186245560646, 0.012111473828554153, 0.019941313192248344, -0.004671473987400532, -0.005358649883419275, 0.017073675990104675, 0.043318506330251694, 0.00161469797603786, 0.02621839940547943, -0.013532077893614769, -0.037953250110149384, -0.01893697865307331, 0.01080319657921791, -0.0035911542363464832, 0.01824980415403843, -0.021725326776504517, -0.02658841758966446, 0.016941526904702187, -0.027566321194171906, 0.0175626277923584, 0.011206251569092274, 0.023020390421152115, 0.0003095181891694665, 0.0006809813203290105, 0.018619822338223457, -0.01965058594942093, 0.007684475742280483, -0.011615914292633533, 0.03668461740016937, 0.018619822338223457, -0.024500461295247078, 0.00023518427042290568, 0.015501100569963455, 0.023258257657289505, 0.007743942551314831, -0.01114017702639103, -0.010367103852331638, 0.02669413760304451, -0.004661562852561474, -0.012851509265601635, -0.012144510634243488, 0.04662223532795906, -0.016082556918263435, -0.045882198959589005, -0.0282270684838295, -0.06417164951562881, 0.04255203902721405, 0.0030757724307477474, -0.009719572961330414, 0.017443694174289703, 0.02436831220984459, 0.00238033733330667, -0.011351616121828556, -0.03903687372803688, -0.032112255692481995, 0.006353072356432676, -0.02699808031320572, 0.007895913906395435, -0.0035779394675046206, -0.013214919716119766, 0.03694891557097435, -0.004744156263768673, 0.01975630410015583, 0.0012108170194551349, -0.034543801099061966, -0.027222733944654465, -0.02382650040090084, -0.0340416319668293, -0.02139495499432087, -0.023020390421152115, 0.028042059391736984, -0.02962784841656685, 0.04794372618198395, -0.008113960735499859, 0.015474670566618443, 0.01688866689801216, 0.0010241562267765403, 0.03938046097755432, -0.007618401199579239, 0.02064170502126217, 0.010373711585998535, 0.0002783392264973372, 0.022002840414643288, 0.017311545088887215, 0.019941313192248344, -0.016254350543022156, 0.006508347578346729, 0.01900305412709713, -0.012382379733026028, -0.01749655418097973, -0.028940673917531967, -0.005451154429465532, 0.04323921725153923, 0.022478578612208366, -0.005973143503069878, -0.012527743354439735, 0.01456284150481224, 0.04442855715751648, -0.012640070170164108, 0.007069981656968594, -0.008959715254604816, 0.010492646135389805, 0.001884777913801372, -0.01695474237203598, -0.02105136588215828, -0.03261442109942436, -0.000521989306434989, 0.0161618459969759, -0.0003617584297899157, 0.00417921831831336, -0.020205611363053322, -0.0197166595607996, -0.0087813138961792, 0.002476145513355732, 0.01814408414065838, 0.014681775122880936, 0.026443053036928177, 0.017760852351784706, 0.01729832962155342, -0.01674330234527588, -0.03671104460954666, -0.011972717009484768, -0.0016708613839000463, 0.017271900549530983, -0.005646074190735817, -0.026429839432239532, 0.0033466783352196217, -0.04123054817318916, 0.01684902235865593, 0.013928525149822235, -0.016293995082378387, -0.0027487031184136868, 0.0232714731246233, 0.01110713928937912, -0.004529413767158985, -0.018514102324843407, 0.04207630455493927, -0.016531864181160927, -0.01695474237203598, -0.007248383481055498, 0.01667722873389721, -0.006237442139536142, 0.0012702841777354479, 0.012686322443187237, -0.028042059391736984, 0.009045612066984177, 0.012263445183634758, -0.013247956521809101, -0.017589056864380836, 0.0134131433442235, -0.009706358425319195, 0.003402841743081808, -0.040041204541921616, 0.05156461521983147, 0.005024973303079605, -0.04958237707614899, 0.04765300080180168, 0.01271275244653225, -0.01965058594942093, 0.051353175193071365, 0.007208738476037979, -0.019016269594430923, 0.021249590441584587, -0.014681775122880936, -0.013624581508338451, -0.010168880224227905, -0.00187321484554559, 0.0428691990673542, -0.007479644380509853, -0.0075655411928892136, -0.014879999682307243, 0.018064795061945915, 0.017205825075507164, 0.011800923384726048, 0.004641740582883358, 0.07210060209035873, -0.005358649883419275, -0.017311545088887215, 0.021130656823515892, -0.0029353639110922813, -0.009190976619720459, -0.0323236919939518, -0.012118080630898476, -0.018606606870889664, -0.02628447487950325, -0.017932645976543427, 0.008682201616466045, -0.025108346715569496, 0.009171154350042343, 0.028359217569231987, -0.009442060254514217, -0.0008052841294556856, -0.033063728362321854, 0.022676801308989525, 0.005100958980619907, 0.054286889731884, -0.013836020603775978, -0.04479857534170151, 0.0004501332005020231, 0.003901704913005233, 0.018950194120407104, 0.00414287718012929, -0.026601633056998253, -0.05056028068065643, 0.0022630549501627684, -0.0028825043700635433, -0.0283327866345644, 0.0020384013187140226, -0.003644014010205865, 0.004103232640773058, 0.005613036919385195, -0.01889733411371708, -0.01801193505525589, 0.02880852483212948, -0.03639388829469681, 0.019901668652892113, 0.01399459969252348, -0.02740774303674698, -0.014972503297030926, 0.03007715567946434, 0.0003654751053545624, 0.011543232016265392, -0.026469483971595764, 0.006098685320466757, 0.008219679817557335, 0.004641740582883358, 0.011424297466874123, -0.025821952149271965, 0.04495715722441673, 0.020932432264089584, 0.025689803063869476, -0.004806926939636469, -0.01725868508219719, -0.003247566521167755, -0.005229804199188948, 0.02938998118042946, 0.006148241460323334, -0.0025240497197955847, -0.01445712149143219, 0.03343374654650688, 0.024685468524694443, -0.01599005237221718, -0.013532077893614769, -0.02098529227077961, -0.03858756646513939, -0.03628816828131676, -0.014206038787961006, 0.024592965841293335, 0.005120781250298023, 0.03803253918886185, -0.02417008765041828, 0.004169307183474302, 0.026363763958215714, 0.009045612066984177, 0.023430051282048225, -0.02399829402565956, 0.011411082930862904, -0.012111473828554153, 0.020139537751674652, -0.0620572604238987, -0.05198749154806137, 0.004506287630647421, 0.005180248524993658, 0.020998507738113403, -0.010182095691561699, 0.0021953284740448, 0.002491012215614319, 0.04297491908073425, -0.0323236919939518, 0.00944866705685854, 0.03055289387702942, -0.01262685563415289, -0.01269953791052103, -0.015329306945204735, 0.01986202411353588, -0.039459750056266785, -0.00757214892655611, 0.0069246175698935986, -0.014523196034133434, -0.01022174023091793, 0.01100802794098854, 0.016373286023736, 0.02029811590909958, -0.0465429462492466, 0.018540531396865845, 0.011285541579127312, -0.035971011966466904, 0.024117227643728256, 0.055079784244298935, 0.009805469773709774, -0.006422450765967369, -0.020945647731423378, -0.0134131433442235, 0.0067858612164855, 0.016994386911392212, 0.00300309038721025, 0.008424511179327965, -0.03784753009676933, 0.0061251153238117695, -0.021725326776504517, -0.021236374974250793, -0.025333000347018242, 0.017813710495829582, 0.011569662019610405, 0.0351252555847168, -0.03496667742729187, 0.01474784966558218, -0.017219040542840958, 0.013756731525063515, -0.014998933300375938, -0.0009019182762131095, 0.03192724660038948, 0.012455061078071594, -0.008682201616466045, -0.03441165015101433, 0.024513674899935722, -0.015210372395813465, 0.005626251921057701, 0.0021622912026941776, -0.017826925963163376, 0.014840354211628437, -0.0030708168633282185, -0.02432866580784321, 0.02464582398533821, -0.001022504409775138, -0.02368113584816456, 0.023601846769452095, 0.004968809895217419, -0.0155671751126647, 0.013518862426280975, 0.010955167934298515, 0.0247779730707407, -0.040384795516729355, 0.009171154350042343, 0.02727559395134449, -0.036763906478881836, 0.01883126050233841, -0.016399715095758438, -0.035019535571336746, 0.020377404987812042, 0.001997104613110423, 0.019161632284522057, -0.005335523746907711, -0.0028412076644599438, -0.014523196034133434, 0.032350122928619385, -0.01900305412709713, 0.028385646641254425, 0.04054337367415428, -0.005636163055896759, -0.0033400708343833685, 0.009851722046732903, -0.02679985575377941, 0.017826925963163376, -0.03028859570622444, 0.001663428032770753, -0.0039050087798386812, -0.03052646294236183, -0.024698683992028236, 0.01992809772491455, -0.03636745736002922, -0.0036836587823927402, 0.01440426241606474, -0.028834953904151917, -0.03496667742729187, -0.020932432264089584, -0.009409022517502308, 0.0012364209396764636, 0.01052568294107914, -0.01299026608467102, -0.061475805938243866, -0.014483551494777203, 0.021236374974250793, 0.011265718378126621, -0.005229804199188948, 0.04059623181819916, -0.0022894847206771374, 0.004023943096399307, -0.04088696092367172, -0.01975630410015583, -0.0018071401864290237, -0.012666500173509121, 0.0006603330257348716, -0.037133924663066864, -0.022531436756253242, 0.00472433352842927, -0.022914670407772064, -0.027064155787229538, -0.005398294422775507, -0.0069114030338823795, 0.029204972088336945, 0.031530797481536865, 0.02027168683707714, 0.011563054285943508, 0.036208879202604294, -0.023403622210025787, -8.450321183772758e-05, -0.017166180536150932, -0.02830635756254196, -0.0031567139085382223, 0.01678294688463211, 0.009660106152296066, -0.00847737118601799, -0.013651011511683464, 0.025716233998537064, 0.025333000347018242, -0.013274386525154114, -0.018170515075325966, -0.018025150522589684, -0.004678081255406141, -0.03496667742729187, 0.048445895314216614, 0.004397264216095209, 0.01951843686401844, -0.044349268078804016, 0.01996774412691593, 0.008431118912994862, -0.0030014384537935257, -0.001555230817757547, -0.006068951915949583, 0.009283481165766716, 0.01399459969252348, -0.008794528432190418, 0.031874384731054306, 0.016188276931643486, 0.022095344960689545, 0.027909910306334496, -0.006851935759186745, -0.008728453889489174, -0.037477511912584305, 0.00707658939063549, -0.04231417179107666, -0.01527644693851471, 0.0018153995042666793, 0.021130656823515892, -0.028042059391736984, 0.03850827366113663, 0.034570228308439255, -0.03776824101805687, 0.027936339378356934, 0.003273996291682124, -0.002063179388642311, -0.021725326776504517, -0.022029271349310875, 0.016148632392287254, 0.020866358652710915, 0.04543289169669151, -0.03237655386328697, -0.02901996299624443, -0.02091921679675579, -0.009461882524192333, -0.014972503297030926, 0.001621305476874113, -0.011629128828644753, 0.01747012324631214, -0.05003168433904648, -0.02044348046183586, 0.008688809350132942, -0.03499310836195946, -0.01732475869357586, 0.02949569933116436, -0.04649008810520172, -0.007334280293434858, 0.02146102860569954, -0.00595662510022521, 0.015672894194722176, 0.014615700580179691, 0.003110461635515094, -0.04770585894584656, 0.024962982162833214, 0.02740774303674698, 0.010162273421883583, 0.02830635756254196, 0.024447601288557053, -0.005428028292953968, -0.023773640394210815, 0.03028859570622444, 0.027698470279574394, -0.038402557373046875, 0.02809491939842701, -0.00592028396204114, -0.013822806067764759, -3.590225242078304e-05, 0.0014404262183234096, -0.003838934004306793, -0.005517228972166777, -0.005705541465431452, 0.0034094492439180613, 0.002519093919545412, -0.019492005929350853, -0.008365044370293617, 0.0023985079023987055, -0.01848767139017582, 0.044587139040231705, 0.019558081403374672, 0.02361506037414074, -0.010327459312975407, 0.04078124091029167, -0.009329733438789845, 0.03657889738678932, 0.04408496990799904, -0.01592397876083851, 0.0311343502253294, -0.007109626661986113, 0.015131082385778427, 0.029522130265831947, -0.006878365762531757, -0.009838507510721684, -0.025650158524513245, -0.0092636588960886, 0.0036968737840652466, 0.022993959486484528, -0.01969023048877716, -0.010089591145515442, -0.00952134933322668, 0.017390834167599678, 0.007889307104051113, 0.0014544670702889562, -0.011285541579127312, 0.09123580157756805, 0.03287871927022934, -0.007003907114267349, -0.00040821710717864335, -0.005788134876638651, -0.0006537255248986185, 0.030473604798316956, -0.017311545088887215, 0.04857804253697395, -0.024698683992028236, -0.0038785787764936686, -0.012640070170164108, -0.014734635129570961, -0.012759004719555378, 0.022756090387701988, -0.00012853574298787862, -0.03377733379602432, -0.009897974319756031, 0.018038364127278328, -0.002218454610556364, 0.010089591145515442, 0.04252561181783676, 0.0022432326804846525, 0.014391046948730946, -0.016796162351965904, -0.012620247900485992, -0.008688809350132942, -0.005566784646362066, 0.006514955312013626, -0.0027156658470630646, -0.01729832962155342, -0.026443053036928177, -0.017351189628243446, 0.001093534636311233, -0.002180461771786213, 0.018408382311463356, -0.018434813246130943, -0.012977050617337227, 0.03272014111280441, -0.017073675990104675, 0.012309697456657887, 0.04760013893246651, -0.010433179326355457, 0.011827352456748486, -0.016227921470999718, -0.004483161494135857, -0.008041278459131718, 0.009065434336662292, 0.03544241562485695, -0.02464582398533821, -0.007248383481055498, -0.016293995082378387, -0.043662093579769135, -0.005087743978947401, 0.0037100885529071093, -0.023773640394210815, 0.035733141005039215, -0.021712113171815872, 0.007677868008613586, 0.011992539279162884, 0.022742876783013344, 0.001744369394145906, -0.018804829567670822, 0.01682259328663349, 0.03311658650636673]\n"
          ]
        }
      ],
      "source": [
        "print(\"First embedding:\", embeddings[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29YsciMeN5iK"
      },
      "source": [
        "Control output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE3IiSUplYee",
        "outputId": "778f8f74-579f-455c-8447-0bc6a07ff1f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks: 9\n",
            "Number of embeddings: 9\n"
          ]
        }
      ],
      "source": [
        "# Check the lengths of the chunks and embeddings\n",
        "num_chunks = len(chunks)\n",
        "print(f\"Number of chunks: {num_chunks}\")\n",
        "print(f\"Number of embeddings: {len(embeddings)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XswfiN5Z1OvT"
      },
      "source": [
        "#  The Pinecone index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# Retrieve the API key from environment variables\n",
        "api_key = os.environ.get('PINECONE_API_KEY')\n",
        "if not api_key:\n",
        "    raise ValueError(\"PINECONE_API_KEY is not set in the environment!\")\n",
        "\n",
        "# Initialize the Pinecone client\n",
        "pc = Pinecone(api_key=api_key)"
      ],
      "metadata": {
        "id": "cKCvBbZPTIjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P---PNLpXeQs"
      },
      "outputs": [],
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "index_name = 'genai-v1'\n",
        "namespace=\"data01\"\n",
        "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
        "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
        "\n",
        "spec = ServerlessSpec(cloud=cloud, region=region)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO7AYljM0gq1",
        "outputId": "59d49600-3c64-48c5-9006-aea3aa81afb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'genaisys': {'vector_count': 3}},\n",
              " 'total_vector_count': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import time\n",
        "import pinecone\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    # if does not exist, create index\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension=1536,  # dimension of the embedding model\n",
        "        metric='cosine',\n",
        "        spec=spec\n",
        "    )\n",
        "    # wait for index to be initialized\n",
        "    time.sleep(1)\n",
        "\n",
        "# connect to index\n",
        "index = pc.Index(index_name)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upserting"
      ],
      "metadata": {
        "id": "yysDraDxk1ks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Pinecone, each record within a vector index comprises several key components:\n",
        "\n",
        "- **ID**: A unique identifier for the record, which can be any string value. This ID is essential for operations like fetching or deleting records by their identifier.\n",
        "\n",
        "- **Values**: An array of numbers representing the dense vector embedding associated with the record. These values capture the essential features of the data point in a high-dimensional space.\n",
        "\n",
        "- **Sparse Values (Optional)**: When utilizing hybrid search capabilities, records can include sparse vector values in addition to dense ones. This allows for more nuanced similarity searches by combining dense and sparse representations. Hybrid search combines keyword-based and semantic search techniques to enhance result relevance and accuracy.    \n",
        "\n",
        "- **Metadata (Optional)**: Additional information associated with the record, stored as key-value pairs. Metadata is useful for filtering search results or adding context to the data.\n",
        "\n",
        "These components collectively define a record in Pinecone's vector index, enabling efficient similarity searches and data retrieval based on vector embeddings."
      ],
      "metadata": {
        "id": "JJpY59P9kr67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "import time\n",
        "import sys\n",
        "\n",
        "start_time = time.time()  # Start timing before the request\n",
        "\n",
        "# Function to calculate the size of a batch\n",
        "def get_batch_size(data, limit=4000000):  # limit set to 4MB to be safe\n",
        "    total_size = 0\n",
        "    batch_size = 0\n",
        "    for item in data:\n",
        "        item_size = sum([sys.getsizeof(v) for v in item.values()])\n",
        "        if total_size + item_size > limit:\n",
        "            break\n",
        "        total_size += item_size\n",
        "        batch_size += 1\n",
        "    return batch_size\n",
        "\n",
        "# Upsert function with namespace\n",
        "def upsert_to_pinecone(batch, batch_size, namespace=\"data01\"):\n",
        "    \"\"\"\n",
        "    Upserts a batch of data to Pinecone under a specified namespace.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        index.upsert(vectors=batch, namespace=namespace)\n",
        "        print(f\"Upserted {batch_size} vectors to namespace '{namespace}'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during upsert: {e}\")\n",
        "\n",
        "# Function to upsert data in batches\n",
        "def batch_upsert(data):\n",
        "    total = len(data)\n",
        "    i = 0\n",
        "    while i < total:\n",
        "        batch_size = get_batch_size(data[i:])\n",
        "        batch = data[i:i + batch_size]\n",
        "        if batch:\n",
        "            upsert_to_pinecone(batch, batch_size, namespace=\"data01\")\n",
        "            i += batch_size\n",
        "            print(f\"Upserted {i}/{total} items...\")  # Display current progress\n",
        "        else:\n",
        "            break\n",
        "    print(\"Upsert complete.\")\n",
        "\n",
        "# Generate IDs for each data item\n",
        "ids = [str(i) for i in range(1, len(chunks) + 1)]\n",
        "\n",
        "# Prepare data for upsert\n",
        "data_for_upsert = [\n",
        "    {\"id\": str(id), \"values\": emb, \"metadata\": {\"text\": chunk}}\n",
        "    for id, (chunk, emb) in zip(ids, zip(chunks, embeddings))\n",
        "]\n",
        "\n",
        "# Upsert data in batches\n",
        "batch_upsert(data_for_upsert)\n",
        "\n",
        "response_time = time.time() - start_time  # Measure response time\n",
        "print(f\"Upsertion response time: {response_time:.2f} seconds\")  # Print response time\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KDId2qIk3CK",
        "outputId": "c6771a05-1fa3-4b99-c176-b275314b3f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upserted 9 vectors to namespace 'data01'.\n",
            "Upserted 9/9 items...\n",
            "Upsert complete.\n",
            "Upsertion response time: 1.11 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcM6mf7hvqCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cef0a3e-adc9-48ae-d270-a677e5ec4929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index stats\n",
            "{'dimension': 1536,\n",
            " 'index_fullness': 0.0,\n",
            " 'namespaces': {'genaisys': {'vector_count': 3}},\n",
            " 'total_vector_count': 3}\n"
          ]
        }
      ],
      "source": [
        "print(\"Index stats\")\n",
        "print(index.describe_index_stats(include_metadata=True))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9kNLfjTfAnFR",
        "O03SZzGGAreV",
        "5NL93eSL-mLi"
      ],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}