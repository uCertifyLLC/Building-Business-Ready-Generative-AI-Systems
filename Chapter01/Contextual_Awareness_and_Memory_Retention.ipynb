{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V44bTqjnKFxZ"
      },
      "source": [
        "#Contextual Awareness and Memory Retention\n",
        "\n",
        "copyright 2025, Denis Rothman\n",
        "\n",
        "This educational notebook is an introduction to varying levels of contextual awareness and memory retention of an AI controller's management of a generative AI models's API:\n",
        "\n",
        "1.Stateless and memoryless session  \n",
        "2.Short-term memory session   \n",
        "3.Long-term memory of multiple sessions   \n",
        "4.Long-term memory of multiple cross-topic sessions   \n",
        "\n",
        "The goal of the notebook is to illustrate some of the main contextual awareness and memory retention approaches that the AI controller of a  Generative AI System uses during conversational sessions.\n",
        "\n",
        "**Usage recommendations:** Run the whole notebook in one session. In this notebook, memory retention is explicit in different cells. In *Chapter 2, Building the  Generative AI model controller*, the functionality of this notebook will be automated and managed by an AI controller.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2VKAYbVikQb"
      },
      "source": [
        "# Setting up the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFfEHkuA3Tbr"
      },
      "source": [
        "This notebook was developed in Google Colab. Colab includes many pre-installed libraries and sets `/content/` as the default directory, meaning you can access files directly by their filename if you wish (e.g., `filename` instead of needing to specify `/content/filename`). This differs from local environments, where you'll often need to install libraries or specify full file paths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8_G2ePO11rQ"
      },
      "source": [
        "## File downloading script\n",
        "\n",
        "grequests contains a script to download files from the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzkCTNNChWAJ"
      },
      "outputs": [],
      "source": [
        "!curl -L https://raw.githubusercontent.com/uCertifyLLC/Building-Business-Ready-Generative-AI-Systems/main/commons/grequests.py --output grequests.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kNLfjTfAnFR"
      },
      "source": [
        "## Installing OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFwDZDHOxhJe"
      },
      "outputs": [],
      "source": [
        "from grequests import download\n",
        "download(\"commons\",\"requirements01.py\")\n",
        "download(\"commons\",\"openai_setup.py\")\n",
        "download(\"commons\",\"openai_api.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7i8j5vnpatH"
      },
      "outputs": [],
      "source": [
        "# Run the setup script to install and import dependencies\n",
        "%run requirements01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O03SZzGGAreV"
      },
      "source": [
        "### Initializing the OpenAI API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDn09vPbAXPT"
      },
      "outputs": [],
      "source": [
        "google_secrets=True #activates Google secrets in Google Colab\n",
        "if google_secrets==True:\n",
        "  import openai_setup\n",
        "  openai_setup.initialize_openai_api()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zer4gyvICLkI"
      },
      "outputs": [],
      "source": [
        "if google_secrets==False: # Uncomment the code and choose any method you wish to initialize the API_KEY\n",
        "  import os\n",
        "  #API_KEY=[YOUR API_KEY]\n",
        "  #os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "  #openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "  #print(\"OpenAI API key initialized successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyRi0ZjbCLkI"
      },
      "source": [
        "### Importing the API call function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lMhv09G0kzr"
      },
      "outputs": [],
      "source": [
        "# Import the API request function\n",
        "import openai_api\n",
        "from openai_api import make_openai_api_call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDj0PUWBrZyt"
      },
      "source": [
        "#  1.Stateless and memoryless session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCRjNVo8DRQH"
      },
      "source": [
        "In this stateless and memoryless example, \"stateless\" indicates that each request is processed independently without retaining information from previous interactions, and \"memoryless\" emphasizes the absence of any built-in mechanism to remember past exchanges. This function is efficient for a single, specific query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjJaT4waPQIh"
      },
      "source": [
        "##Semantic query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S5OplfgGmaZ"
      },
      "outputs": [],
      "source": [
        "# API message\n",
        "uinput = \"Hawai is on a geological volcano system. Explain:\"\n",
        "mrole = \"system\"\n",
        "mcontent = \"You are an expert in geology.\"\n",
        "user_role = \"user\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXCAITeoEHBt"
      },
      "outputs": [],
      "source": [
        "# API function call\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn7-q-SJPaHD"
      },
      "source": [
        "## Episodic query with a semantic undertone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceR4oudbPgMO"
      },
      "outputs": [],
      "source": [
        "# API message\n",
        "uinput = \"I vividly remember my family's move to Hawaii in the 1970s, how they embraced the warmth of its gentle breezes, the joy of finding a steady job, and the serene beauty that surrounded them. Sum this up in one nice sentence from a personal perspective:?\"\n",
        "mrole = \"system\"\n",
        "mcontent = \"You are an expert in geology.\"\n",
        "user_role = \"user\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icAwaNBhb--z"
      },
      "source": [
        "Augmented input from a text message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl1EizvucDhi"
      },
      "outputs": [],
      "source": [
        "text_message='I agree, we had a wonderful time there.'\n",
        "uninput=text_message+uinput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxiFf7AuPi4V"
      },
      "outputs": [],
      "source": [
        "# API function call\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpk6IC5KN17P"
      },
      "source": [
        "## Stateless and memoryless verification\n",
        "\n",
        "Confirming the session is memoryless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TCN0i3hN504"
      },
      "outputs": [],
      "source": [
        "# API message\n",
        "uinput = \"What question did I just ask you?\"\n",
        "mrole = \"system\"\n",
        "mcontent = \"You already have this information\"\n",
        "user_role = \"user\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe9wz2fGOScH"
      },
      "outputs": [],
      "source": [
        "# API function call\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwIbj4GGPS3_"
      },
      "source": [
        "# 2.Short-term memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf9lmXGmP6ZM"
      },
      "source": [
        "A request is processed and retains information from previous interaction through a built-in mechanism to remember a past exchange. This function is efficient for a single session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TldIxfeuQSTl"
      },
      "outputs": [],
      "source": [
        "uinput = \"Hawai is on a geological volcano system. Explain:\"\n",
        "mrole = \"system\"\n",
        "mcontent = \"You are an expert in geology.\"\n",
        "user_role = \"user\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teXQsk4rQWdt"
      },
      "outputs": [],
      "source": [
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXMv8bqFQszU"
      },
      "source": [
        "Let's now simumlate the conversational AI feature that is automated in the core module of an AI controller in *Chapter 2, Building the AI_Controller*.\n",
        "\n",
        "The session now remembers the state of the dialog."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrF2kbNlQfrb"
      },
      "outputs": [],
      "source": [
        "ninput = \"Sum up your previous response in a short sentence in a maximum of 20 words.\"\n",
        "uinput=\"The current dialog session is :\" + uinput + response + ninput\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJeM_0L3ZYtN"
      },
      "outputs": [],
      "source": [
        "print(\"New response:\",response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnlXAIbuVjbn"
      },
      "source": [
        "# 3.Long-term memory of multiple sessions\n",
        "\n",
        "**Note**: To run this cell, make sure that you have run the 2.Short-term memory section first without closing the session."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykca49tl3kq1"
      },
      "source": [
        "#### Saving the previous session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NclxG-kiyl_7"
      },
      "outputs": [],
      "source": [
        "session01=response\n",
        "print(session01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEV9zA6U21Af"
      },
      "source": [
        "#### Without long-term memory between sessions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_oVA8P52sF3"
      },
      "outputs": [],
      "source": [
        "uinput=\"Is in safe to go there on vacation\"\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlbLA2kd25hl"
      },
      "source": [
        "#### With long-term memory between sessions\n",
        "\n",
        "In this scenario,the output of a previous request is added to the input of the previous request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6NOImrg2dww"
      },
      "outputs": [],
      "source": [
        "ninput = \"Let's continue our dialog.\"\n",
        "uinput=ninput + session01 + \"Would it be safe to go there on vacation?\"\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "#print(\"Dialog:\", uinput,\"\\n\") // optional\n",
        "print(\"Response:\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCzH3cmaWHrh"
      },
      "source": [
        "# 4.Long-term memory of multiple cross-topic sessions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0nh4pOZ3f1b"
      },
      "source": [
        "#### Saving the session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7Kozrox3slj"
      },
      "outputs": [],
      "source": [
        "session02=uinput + response\n",
        "print(session02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTeqICyJ4D25"
      },
      "outputs": [],
      "source": [
        "ninput =\"I would like to organize a geological visit in Arizona.\"\n",
        "uinput=ninput+\"Where should I start?\"\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "print(\"Dialog:\", uinput,\"\\n\") #optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dx2BrqsqmGX2"
      },
      "outputs": [],
      "source": [
        "print(\"Response:\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "livVllea4YCH"
      },
      "outputs": [],
      "source": [
        "session02=response\n",
        "ninput=\"Sum up this dialog in a short paragraph:\"\n",
        "uinput=ninput+ session01 + session02\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "#print(\"Dialog:\", uinput,\"\\n\")#optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhyAu_BunK1q"
      },
      "outputs": [],
      "source": [
        "print(\"Response:\", response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
